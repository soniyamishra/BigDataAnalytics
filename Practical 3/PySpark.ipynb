{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soniyamishra/BigDataAnalytics/blob/main/Practical%203/PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "safAkSX4Rcvm"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFrcLUdlVy8Q"
      },
      "source": [
        "!wget -q https://mirrors.estointernet.in/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORYoDm79Vzz3"
      },
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rzvFjAnV2_A"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOXF2eq5WtKv"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TS7PBGAnW515",
        "outputId": "3487da28-79e2-49a4-a5b4-9827e3ccbf5e"
      },
      "source": [
        "os.environ[\"SPARK_HOME\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.1.2-bin-hadoop3.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJlcJGT4XD5H"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pop3HsZEXKlW"
      },
      "source": [
        "pip install spark-nlp==2.4.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bkkIJYGXQbe",
        "outputId": "76befd84-e802-4b78-a474-c12e60b73c4a"
      },
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version:  2.4.2\n",
            "Apache Spark version:  3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aoKON1mZEBY",
        "outputId": "149c3e23-6cc9-439b-9076-2122b4eb3f27"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        " \n",
        "spark = SparkSession.builder.appName(\"Create First DataFrame PySpark 3.0\").getOrCreate()\n",
        "print(spark.sparkContext.appName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pyspark-shell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZFkCoqrXUsO",
        "outputId": "e6909c58-9d86-4c5b-90e1-e8d20d12be9f"
      },
      "source": [
        " \n",
        "data = [('James','','Smith','1991-04-01','M',3000),\n",
        "  ('Michael','Rose','','2000-05-19','M',4000),\n",
        "  ('Robert','','Williams','1978-09-05','M',4000),\n",
        "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
        "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
        "]\n",
        " \n",
        "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[firstname: string, middlename: string, lastname: string, dob: string, gender: string, salary: bigint]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4fURSpPbtF0"
      },
      "source": [
        "# **Create DataFrames**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svZ2qsZlaw8S",
        "outputId": "624b41a3-0308-44b3-82eb-6f22d0f8c35b"
      },
      "source": [
        "# Create DataFrames\n",
        "# import pyspark class Row from module sql\n",
        "from pyspark.sql import *\n",
        "\n",
        "# Create Example Data - Departments and Employees\n",
        "\n",
        "# Create the Departments\n",
        "department1 = Row(id='123456', name='Computer Science')\n",
        "department2 = Row(id='789012', name='Mechanical Engineering')\n",
        "department3 = Row(id='345678', name='Theater and Drama')\n",
        "department4 = Row(id='901234', name='Indoor Recreation')\n",
        "\n",
        "# Create the Employees\n",
        "Employee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\n",
        "employee1 = Employee('michael', 'armbrust', 'no-reply@berkeley.edu', 100000)\n",
        "employee2 = Employee('xiangrui', 'meng', 'no-reply@stanford.edu', 120000)\n",
        "employee3 = Employee('matei', None, 'no-reply@waterloo.edu', 140000)\n",
        "employee4 = Employee(None, 'wendell', 'no-reply@berkeley.edu', 160000)\n",
        "employee5 = Employee('michael', 'jackson', 'no-reply@neverla.nd', 80000)\n",
        "\n",
        "# Create the DepartmentWithEmployees instances from Departments and Employees\n",
        "departmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2])\n",
        "departmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4])\n",
        "departmentWithEmployees3 = Row(department=department3, employees=[employee5, employee4])\n",
        "departmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])\n",
        "\n",
        "print(department1)\n",
        "print(employee2)\n",
        "print(departmentWithEmployees1.employees[0].email)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row(id='123456', name='Computer Science')\n",
            "Row(firstName='xiangrui', lastName='meng', email='no-reply@stanford.edu', salary=120000)\n",
            "no-reply@berkeley.edu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6lJZFZgb0cX"
      },
      "source": [
        "# Create DataFrames from a list of the row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4QJhSRgbHWN"
      },
      "source": [
        "departmentsWithEmployeesSeq1 = [departmentWithEmployees1, departmentWithEmployees2]\n",
        "df1 = spark.createDataFrame(departmentsWithEmployeesSeq1)\n",
        " \n",
        "display(df1)\n",
        " \n",
        "departmentsWithEmployeesSeq2 = [departmentWithEmployees3, departmentWithEmployees4]\n",
        "df2 = spark.createDataFrame(departmentsWithEmployeesSeq2)\n",
        " \n",
        "display(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lAjiUyKbN2k",
        "outputId": "8415e7d4-37d9-4d11-d3a0-4c20262234d0"
      },
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "explodeDF = unionDF.select(explode(\"employees\").alias(\"e\"))\n",
        "flattenDF = explodeDF.selectExpr(\"e.firstName\", \"e.lastName\", \"e.email\", \"e.salary\")\n",
        "\n",
        "flattenDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+--------------------+------+\n",
            "|firstName|lastName|               email|salary|\n",
            "+---------+--------+--------------------+------+\n",
            "|  michael|armbrust|no-reply@berkeley...|100000|\n",
            "| xiangrui|    meng|no-reply@stanford...|120000|\n",
            "|    matei|    null|no-reply@waterloo...|140000|\n",
            "|     null| wendell|no-reply@berkeley...|160000|\n",
            "|  michael| jackson| no-reply@neverla.nd| 80000|\n",
            "|     null| wendell|no-reply@berkeley...|160000|\n",
            "| xiangrui|    meng|no-reply@stanford...|120000|\n",
            "|    matei|    null|no-reply@waterloo...|140000|\n",
            "+---------+--------+--------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}